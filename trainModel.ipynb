{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datorseenede projekt \n",
    "#### Projektet i kursen datorseende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 884 (2914.2 MB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchvision 0.21.0+cu126\n",
      "Uninstalling torchvision-0.21.0+cu126:\n",
      "  Successfully uninstalled torchvision-0.21.0+cu126\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'D:\\Programs\\anaconda\\envs\\opencv\\Lib\\site-packages\\~orchvision'.\n",
      "You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall torchvision -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchvision-0.21.0%2Bcu126-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0+cu126 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torchvision) (2.6.0+cu126)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch==2.6.0+cu126->torchvision) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch==2.6.0+cu126->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch==2.6.0+cu126->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch==2.6.0+cu126->torchvision) (3.1.5)\n",
      "Requirement already satisfied: fsspec in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch==2.6.0+cu126->torchvision) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch==2.6.0+cu126->torchvision) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch==2.6.0+cu126->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0+cu126->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from jinja2->torch==2.6.0+cu126->torchvision) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cu126/torchvision-0.21.0%2Bcu126-cp313-cp313-win_amd64.whl (6.1 MB)\n",
      "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.1 MB 1.3 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.8/6.1 MB 1.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.0/6.1 MB 1.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.3/6.1 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.6/6.1 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.8/6.1 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.1/6.1 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 2.4/6.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.6/6.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.9/6.1 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 3.1/6.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 3.4/6.1 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.7/6.1 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.9/6.1 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.2/6.1 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.5/6.1 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.7/6.1 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 5.0/6.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.2/6.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.1/6.1 MB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.21.0+cu126\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install torchvision --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installationer\n",
    "Installerar paket som behövs för exekveringen av koden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split-folders in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ultralytics in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (8.3.89)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (4.10.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (1.15.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (2.6.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (0.21.0+cu126)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu126Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (2.6.0+cu126)\n",
      "Requirement already satisfied: torchvision in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (0.21.0+cu126)\n",
      "Requirement already satisfied: torchaudio in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (2.6.0+cu126)\n",
      "Requirement already satisfied: filelock in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\programs\\anaconda\\envs\\opencv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install split-folders\n",
    "%pip install --upgrade ultralytics\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spjälka data \n",
    "Spjälker data för att kunna användas i yolo modellen. Data spjälks till test, train och val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 5302 files [00:24, 212.72 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "input_folder = \"./input-data\"\n",
    "output_folder = \"./dataset\"\n",
    "\n",
    "splitfolders.ratio(input_folder,output = output_folder, seed=42, ratio=(0.7,0.2,0.1),group_prefix=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testa installation\n",
    "för att kolla att allt är installerat korrekt och att versionerna matchar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "0.21.0+cu126\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)  # Ska vara 2.6.0+cu126\n",
    "print(torchvision.__version__)  # Ska ha +cu126, inte +cpu\n",
    "print(torch.cuda.is_available())  # Ska vara True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utför träningen \n",
    "Träna en yolov11 model med datan som vi har, med passande parametrar för egen dator att köra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(\"yolo11s.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Träna modelen på dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.92 available  Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1mbatch_size\u001b[0m' is not a valid YOLO argument. Similar arguments are i.e. ['batch=16'].\n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\rasmu\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v34a4737bf41859a8a37d9c0f756f172d106f6ebda.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of frozenset({'detect', 'classify', 'pose', 'obb', 'segment'})\n                MODE (required) is one of frozenset({'predict', 'export', 'benchmark', 'val', 'track', 'train'})\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video/file.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92mc:\\Users\\rasmu\\anaconda3\\envs\\labelstudio\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3546\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[8]\u001b[39m\u001b[92m, line 2\u001b[39m\n    results = model.train(\n",
      "  File \u001b[92mc:\\Users\\rasmu\\anaconda3\\envs\\labelstudio\\Lib\\site-packages\\ultralytics\\engine\\model.py:804\u001b[39m in \u001b[95mtrain\u001b[39m\n    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "  File \u001b[92mc:\\Users\\rasmu\\anaconda3\\envs\\labelstudio\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:102\u001b[39m in \u001b[95m__init__\u001b[39m\n    self.args = get_cfg(cfg, overrides)\n",
      "  File \u001b[92mc:\\Users\\rasmu\\anaconda3\\envs\\labelstudio\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:310\u001b[39m in \u001b[95mget_cfg\u001b[39m\n    check_dict_alignment(cfg, overrides)\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rasmu\\anaconda3\\envs\\labelstudio\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:497\u001b[39m\u001b[36m in \u001b[39m\u001b[35mcheck_dict_alignment\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mraise SyntaxError(string + CLI_HELP_MSG) from e\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>\u001b[39m\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m '\u001b[31m\u001b[1mbatch_size\u001b[0m' is not a valid YOLO argument. Similar arguments are i.e. ['batch=16'].\n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\rasmu\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v34a4737bf41859a8a37d9c0f756f172d106f6ebda.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of frozenset({'detect', 'classify', 'pose', 'obb', 'segment'})\n                MODE (required) is one of frozenset({'predict', 'export', 'benchmark', 'val', 'track', 'train'})\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video/file.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "# Train model on custom dataset\n",
    "results = model.train(\n",
    "    data=\"config.yaml\",\n",
    "    project=\"./output\",\n",
    "    device='cuda:0',\n",
    "    epochs=100,\n",
    "    batch=-1,  \n",
    "    imgsz=512,\n",
    "    workers=12,\n",
    "    amp=True, \n",
    "    name=\"yolo11_50\",\n",
    "    exist_ok=True,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Som följande kör vi validering på vår model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.88  Python-3.11.11 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce GTX 1660, 6144MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Programming\\cv-25-project\\dataset\\val\\labels.cache... 14 images, 104 backgrounds, 0 corrupt: 100%|██████████| 118/118 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        118         22     0.0846      0.686     0.0928     0.0743\n",
      "                 skier         11         15     0.0891        0.8        0.1     0.0758\n",
      "           snowboarder          5          7     0.0801      0.571     0.0855     0.0729\n",
      "Speed: 1.4ms preprocess, 7.4ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labelstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
